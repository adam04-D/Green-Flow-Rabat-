{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06af9c3f",
   "metadata": {},
   "source": [
    "# GreenFlow Rabat â€” Smart Traffic Intelligence\n",
    "### Hackathon RamadnIA 2026\n",
    "\n",
    "**Objective:** Transform existing CCTV cameras into smart traffic sensors using Edge AI.\n",
    "\n",
    "**Pipeline Overview:**\n",
    "1. Extract frames from local Rabat driving footage\n",
    "2. Annotate with Roboflow Label Assist (4 classes)\n",
    "3. Train YOLO11n with small-object optimizations\n",
    "4. Export to ONNX/NCNN for Raspberry Pi 5 / Jetson\n",
    "5. Real-time RTSP inference â†’ JSON webhook â†’ n8n orchestration\n",
    "\n",
    "**Classes:** `License Plate` Â· `Car` Â· `Grand Taxi` Â· `Triporteur`\n",
    "\n",
    "**Privacy:** 100% local processing. No images leave the edge device."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c78ea0",
   "metadata": {},
   "source": [
    "## Phase 1: Environment Setup\n",
    "Installs all dependencies and verifies the hardware (CPU vs GPU).  \n",
    "Run this cell once per session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04067db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All packages installed.\n"
     ]
    }
   ],
   "source": [
    "# ---------- Install Dependencies ----------\n",
    "# We use subprocess instead of !pip to work on ANY platform\n",
    "# (local, Colab, Kaggle, Paperspace â€” no Colab-specific syntax).\n",
    "\n",
    "import subprocess, sys\n",
    "\n",
    "packages = [\n",
    "    \"ultralytics\",            # YOLO11n â€” our detection model\n",
    "    \"roboflow\",               # Dataset download + annotation API\n",
    "    \"opencv-python-headless\", # Image/video processing (headless = no GUI needed)\n",
    "    \"requests\",               # HTTP calls to n8n webhooks\n",
    "]\n",
    "\n",
    "for pkg in packages:\n",
    "    subprocess.check_call(\n",
    "        [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg],\n",
    "        stdout=subprocess.DEVNULL  # suppress noisy pip output\n",
    "    )\n",
    "\n",
    "print(\"All packages installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "746279ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "  GreenFlow Rabat â€” Environment Report\n",
      "=============================================\n",
      "  Python :  3.12.12\n",
      "  PyTorch:  2.9.0+cpu\n",
      "  CUDA   :  False\n",
      "  GPU    :  None (CPU mode)\n",
      "  Tip    :  Connect Colab GPU for training (Phase 5)\n",
      "  OS     :  Linux x86_64\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "# ---------- Hardware Check ----------\n",
    "# This tells us if we have a GPU available.\n",
    "# Training on CPU = hours.  Training on GPU = minutes.\n",
    "\n",
    "import torch\n",
    "import platform\n",
    "\n",
    "print(\"=\" * 45)\n",
    "print(\"  GreenFlow Rabat â€” Environment Report\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"  Python :  {platform.python_version()}\")\n",
    "print(f\"  PyTorch:  {torch.__version__}\")\n",
    "print(f\"  CUDA   :  {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  GPU    :  {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  VRAM   :  {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"  GPU    :  None (CPU mode)\")\n",
    "    print(\"  Tip    :  Connect Colab GPU for training (Phase 5)\")\n",
    "\n",
    "print(f\"  OS     :  {platform.system()} {platform.machine()}\")\n",
    "print(\"=\" * 45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47941747",
   "metadata": {},
   "source": [
    "## Phase 2: Frame Extraction\n",
    "Extract 1 frame every 5 seconds from the Rabat driving video.  \n",
    "Output: ~480 JPEG images saved to `data/frames/` for Roboflow annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "129c1f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "Video found: (1457 MB)\n",
      "Prefix: rabat_night_XXXX.jpg\n"
     ]
    }
   ],
   "source": [
    "# ---------- Configuration ----------\n",
    "# We mount Google Drive to access the video AND save frames there.\n",
    "# Everything stays on Drive â€” permanent, survives session restarts.\n",
    "#\n",
    "# WORKFLOW: For each video, change VIDEO_PATH and PREFIX, then re-run cells 6+7.\n",
    "#   Run 1: day    â†’ \"rabat_day_0000.jpg\"   (already done with 523 frames)\n",
    "#   Run 2: night  â†’ \"rabat_night_0000.jpg\"\n",
    "#   Run 3: rain   â†’ \"rabat_rain_0000.jpg\"\n",
    "#   Run 4: dusk   â†’ \"rabat_dusk_0000.jpg\"\n",
    "\n",
    "from pathlib import Path\n",
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive (a browser popup will ask for permission once)\n",
    "drive.mount(\"/content/drive\")\n",
    "\n",
    "# ---- CHANGE THESE TWO FOR EACH VIDEO ----\n",
    "VIDEO_PATH = \"/content/drive/MyDrive/GreenFlow-Rabat/YTDown.com_YouTube_Rabat-4K-Night-Drive-Driving-Downtown-Re_Media_aFtBUlb9yj8_001_1080p.mp4\"\n",
    "PREFIX = \"rabat_night\"  # Change per video: \"rabat_day\", \"rabat_night\", \"rabat_rain\", \"rabat_dusk\"\n",
    "# ------------------------------------------\n",
    "\n",
    "# Extracted frames saved to your existing Drive folder (permanent storage)\n",
    "OUTPUT_DIR = Path(\"/content/drive/MyDrive/GreenFlow-Rabat/Extracted_Frames\")\n",
    "INTERVAL_SEC = 5  # Extract 1 frame every N seconds\n",
    "\n",
    "# Sanity check\n",
    "import os\n",
    "if os.path.exists(VIDEO_PATH):\n",
    "    size_mb = os.path.getsize(VIDEO_PATH) / 1e6\n",
    "    print(f\"Video found: ({size_mb:.0f} MB)\")\n",
    "    print(f\"Prefix: {PREFIX}_XXXX.jpg\")\n",
    "else:\n",
    "    print(f\"Video NOT found at: {VIDEO_PATH}\")\n",
    "    print(\"Check the filename in your Drive folder and update VIDEO_PATH above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb6f3baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video info: 30.0 FPS | 95,040 total frames | 52.9 min\n",
      "Strategy:   1 frame every 5s = every 149 frames\n",
      "Expected:   ~637 frames to extract\n",
      "\n",
      "  Saved 50 frames...\n",
      "  Saved 100 frames...\n",
      "  Saved 150 frames...\n",
      "  Saved 200 frames...\n",
      "  Saved 250 frames...\n",
      "  Saved 300 frames...\n",
      "  Saved 350 frames...\n",
      "  Saved 400 frames...\n",
      "  Saved 450 frames...\n",
      "  Saved 500 frames...\n",
      "  Saved 550 frames...\n",
      "  Saved 600 frames...\n",
      "\n",
      "Done! Extracted 638 frames â†’ /content/drive/MyDrive/GreenFlow-Rabat/Extracted_Frames/\n"
     ]
    }
   ],
   "source": [
    "# ---------- Extract Frames ----------\n",
    "import cv2\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "\n",
    "# Read video metadata\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)                    # Frames per second of the video\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # Total number of frames\n",
    "duration_min = total_frames / fps / 60              # Video length in minutes\n",
    "frame_step = int(fps * INTERVAL_SEC)                # How many frames to skip between captures\n",
    "\n",
    "print(f\"Video info: {fps:.1f} FPS | {total_frames:,} total frames | {duration_min:.1f} min\")\n",
    "print(f\"Strategy:   1 frame every {INTERVAL_SEC}s = every {frame_step} frames\")\n",
    "print(f\"Expected:   ~{total_frames // frame_step} frames to extract\\n\")\n",
    "\n",
    "# Main extraction loop\n",
    "saved = 0\n",
    "frame_idx = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()       # Read one frame from the video\n",
    "    if not ret:                   # ret is False when video ends\n",
    "        break\n",
    "    \n",
    "    if frame_idx % frame_step == 0:  # Only save every Nth frame\n",
    "        # Mask watermark \"STREET.MA\" at bottom-right corner\n",
    "        h, w = frame.shape[:2]\n",
    "        frame[h-120:h, w-450:w] = 0  # Black out a 450x120 px rectangle\n",
    "        \n",
    "        filename = OUTPUT_DIR / f\"{PREFIX}_{saved:04d}.jpg\"\n",
    "        cv2.imwrite(str(filename), frame)\n",
    "        saved += 1\n",
    "        \n",
    "        # Progress update every 50 saved frames\n",
    "        if saved % 50 == 0:\n",
    "            print(f\"  Saved {saved} frames...\")\n",
    "    \n",
    "    frame_idx += 1\n",
    "\n",
    "cap.release()  # Always release the video capture when done\n",
    "\n",
    "print(f\"\\nDone! Extracted {saved} frames â†’ {OUTPUT_DIR}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffad88b",
   "metadata": {},
   "source": [
    "## Phase 2.5: Automated Frame Cleaning\n",
    "Smart filtering to remove near-duplicates, severely blurred, and pitch-black frames.  \n",
    "**Safety rule:** Nothing is deleted â€” rejected frames are *moved* to a `rejected_frames/` folder for manual review.\n",
    "\n",
    "| Filter | Method | Day | Night | Rain |\n",
    "|--------|--------|-----|-------|------|\n",
    "| Near-duplicates | Perceptual hash (hamming dist) | Main filter | Active | Active |\n",
    "| Motion blur | Laplacian variance | Strict (50) | Lenient (15) | Moderate (25) |\n",
    "| Extreme darkness | Mean pixel intensity | Rarely triggers | Main filter | Rarely triggers |\n",
    "\n",
    "**Targets:** 522â†’~480 Day Â· 637â†’~320 Night Â· 300â†’~230 Rain â‰ˆ **~1,000 clean frames**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bd09327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imagehash installed âœ“\n"
     ]
    }
   ],
   "source": [
    "# ---------- Install imagehash (one-time) ----------\n",
    "# imagehash provides perceptual hashing â€” it converts images into\n",
    "# compact \"fingerprints\" so we can detect near-duplicates by comparing\n",
    "# fingerprints instead of pixel-by-pixel (which is too slow and fragile).\n",
    "\n",
    "import subprocess, sys\n",
    "\n",
    "subprocess.check_call(\n",
    "    [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"imagehash\"],\n",
    "    stdout=subprocess.DEVNULL\n",
    ")\n",
    "print(\"imagehash installed âœ“\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b837ad6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (ipython-input-693915021.py, line 47)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-693915021.py\"\u001b[0;36m, line \u001b[0;32m47\u001b[0m\n\u001b[0;31m    print(f\"Hash distance threshold: {HASH_DISTANCE_THRESH}\") for c, cfg in CONDITIONS.items():\u001b[0m\n\u001b[0m                                                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# ---------- Configuration & Folder Setup ----------\n",
    "# Source: your existing Extracted_Frames folder on Drive\n",
    "# Output: two NEW sibling folders â€” kept_frames/ and rejected_frames/\n",
    "# Each mirrors the Day/Night/Rain subfolder structure.\n",
    "\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\")\n",
    "\n",
    "# ---- Paths (adjust if your folder names differ) ----\n",
    "BASE_DIR = Path(\"/content/drive/MyDrive/GreenFlow-Rabat\")\n",
    "SOURCE_DIR = BASE_DIR / \"Extracted_Frames\"     # Where all 1,459 frames live now\n",
    "KEPT_DIR   = BASE_DIR / \"kept_frames\"           # Clean frames go here â†’ Roboflow\n",
    "REJECT_DIR = BASE_DIR / \"rejected_frames\"       # Rejected frames go here â†’ manual review\n",
    "\n",
    "# Subfolder mapping: prefix pattern â†’ condition label\n",
    "# This tells the script which threshold profile to use for each image.\n",
    "#\n",
    "# IMPORTANT: Day frames are named \"rabat_0000.jpg\" (no 'day' keyword),\n",
    "# while night/rain have explicit prefixes (\"rabat_night_\", \"rabat_rain_\").\n",
    "# We use \"exclude\" to prevent the day matcher from grabbing night/rain files.\n",
    "CONDITIONS = {\n",
    "    \"day\":   {\"prefix\": \"rabat_\",      \"exclude\": [\"rabat_night\", \"rabat_rain\"], \"blur_thresh\": 50, \"dark_thresh\": 20},\n",
    "    \"night\": {\"prefix\": \"rabat_night\",  \"exclude\": [],                             \"blur_thresh\": 15, \"dark_thresh\": 30},\n",
    "    \"rain\":  {\"prefix\": \"rabat_rain\",   \"exclude\": [],                             \"blur_thresh\": 25, \"dark_thresh\": 20},\n",
    "}\n",
    "\n",
    "# Similarity threshold: perceptual hash hamming distance.\n",
    "# Two images with hash distance <= this value are considered duplicates.\n",
    "# Lower = stricter (only very similar rejected). Higher = more aggressive.\n",
    "HASH_DISTANCE_THRESH = 4   # ~94% similarity on a 64-bit hash\n",
    "\n",
    "# Create output folders\n",
    "for condition in CONDITIONS:\n",
    "    (KEPT_DIR / condition).mkdir(parents=True, exist_ok=True)\n",
    "    (REJECT_DIR / condition).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Source:   {SOURCE_DIR}\")\n",
    "print(f\"Kept:     {KEPT_DIR}\")\n",
    "print(f\"Rejected: {REJECT_DIR}\")\n",
    "print(f\"\\nSubfolders created: {list(CONDITIONS.keys())}\")\n",
    "print(f\"Hash distance threshold: {HASH_DISTANCE_THRESH}\")\n",
    "for c, cfg in CONDITIONS.items():\n",
    "    print(f\"  {c:6s} â†’ blur < {cfg['blur_thresh']}  |  dark < {cfg['dark_thresh']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a202bdf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering functions loaded âœ“\n",
      "  compute_blur_score(img)   â†’ float (higher = sharper)\n",
      "  is_too_blurry(img, thr)   â†’ (bool, score)\n",
      "  is_too_dark(img, thr)     â†’ (bool, mean_intensity)\n",
      "  compute_phash(path)       â†’ imagehash object\n",
      "  are_duplicates(h1,h2,thr) â†’ bool\n"
     ]
    }
   ],
   "source": [
    "# ---------- Filtering Functions ----------\n",
    "# Each function returns True if the image FAILS the quality check\n",
    "# (i.e., should be rejected).\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imagehash\n",
    "from PIL import Image\n",
    "\n",
    "def compute_blur_score(img_bgr):\n",
    "    \"\"\"\n",
    "    Variance of the Laplacian â€” the classic blur detector.\n",
    "    \n",
    "    HOW IT WORKS:\n",
    "    - The Laplacian operator detects edges (rapid intensity changes).\n",
    "    - A sharp image has many strong edges â†’ high variance.\n",
    "    - A blurry image has few/weak edges â†’ low variance.\n",
    "    \n",
    "    Returns a float: higher = sharper. Typical ranges:\n",
    "      - Very sharp:  200+\n",
    "      - Acceptable:  50â€“200\n",
    "      - Blurry:      < 50  (day)  /  < 15 (night)\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    laplacian = cv2.Laplacian(gray, cv2.CV_64F)  # 2nd derivative of intensity\n",
    "    return laplacian.var()                         # Variance = spread of edge strengths\n",
    "\n",
    "\n",
    "def is_too_blurry(img_bgr, threshold):\n",
    "    \"\"\"Check if frame is too blurry for the given condition's threshold.\"\"\"\n",
    "    score = compute_blur_score(img_bgr)\n",
    "    return score < threshold, score\n",
    "\n",
    "\n",
    "def is_too_dark(img_bgr, threshold):\n",
    "    \"\"\"\n",
    "    Check if frame is too dark to contain useful information.\n",
    "    \n",
    "    HOW IT WORKS:\n",
    "    - Convert to grayscale (single channel, 0=black, 255=white).\n",
    "    - Compute the mean pixel value across the entire image.\n",
    "    - If the average is below the threshold, the frame is essentially\n",
    "      pitch-black or so dark that no vehicle features are distinguishable.\n",
    "    \n",
    "    Night frames naturally have lower means (~40â€“80), so the threshold\n",
    "    is set per-condition to avoid false rejections.\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    mean_intensity = np.mean(gray)\n",
    "    return mean_intensity < threshold, mean_intensity\n",
    "\n",
    "\n",
    "def compute_phash(img_path):\n",
    "    \"\"\"\n",
    "    Compute a perceptual hash (pHash) for an image.\n",
    "    \n",
    "    HOW IT WORKS:\n",
    "    - Resize image to 32x32, convert to grayscale.\n",
    "    - Apply DCT (Discrete Cosine Transform) â€” like a 2D frequency analysis.\n",
    "    - Keep only the low-frequency components (overall structure, not detail).\n",
    "    - Threshold to produce a 64-bit binary hash.\n",
    "    \n",
    "    Two visually similar images produce nearly identical hashes,\n",
    "    even if they differ in brightness, compression, or minor shifts.\n",
    "    \n",
    "    Hamming distance = number of bits that differ between two hashes.\n",
    "    - 0 = identical images\n",
    "    - 1-4 = near-duplicates (traffic jam consecutive frames)\n",
    "    - 10+ = clearly different scenes\n",
    "    \"\"\"\n",
    "    pil_img = Image.open(str(img_path))\n",
    "    return imagehash.phash(pil_img)\n",
    "\n",
    "\n",
    "def are_duplicates(hash1, hash2, threshold):\n",
    "    \"\"\"\n",
    "    Compare two perceptual hashes.\n",
    "    The '-' operator gives the Hamming distance (number of differing bits).\n",
    "    \"\"\"\n",
    "    return (hash1 - hash2) <= threshold\n",
    "\n",
    "print(\"Filtering functions loaded âœ“\")\n",
    "print(f\"  compute_blur_score(img)   â†’ float (higher = sharper)\")\n",
    "print(f\"  is_too_blurry(img, thr)   â†’ (bool, score)\")\n",
    "print(f\"  is_too_dark(img, thr)     â†’ (bool, mean_intensity)\")\n",
    "print(f\"  compute_phash(path)       â†’ imagehash object\")\n",
    "print(f\"  are_duplicates(h1,h2,thr) â†’ bool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422b3e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================================\n",
      "  Processing: DAY\n",
      "  Blur threshold: 50  |  Dark threshold: 20\n",
      "=======================================================\n",
      "  Found 0 frames with prefix 'rabat_day'\n",
      "  âš  No frames found! Check that PREFIX matches your filenames.\n",
      "\n",
      "=======================================================\n",
      "  Processing: NIGHT\n",
      "  Blur threshold: 15  |  Dark threshold: 30\n",
      "=======================================================\n",
      "  Found 638 frames with prefix 'rabat_night'\n",
      "  Copying to kept_frames/night/ ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-3376502694.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  Copying to kept_frames/{condition}/ ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkept_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# Now work exclusively inside kept_dir â€” move rejects out of it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.12/shutil.py\u001b[0m in \u001b[0;36mcopy2\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    473\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m     \u001b[0mcopystat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.12/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    271\u001b[0m                     \u001b[0;32melif\u001b[0m \u001b[0m_USE_CP_SENDFILE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m                             \u001b[0m_fastcopy_sendfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m                             \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m                         \u001b[0;32mexcept\u001b[0m \u001b[0m_GiveupOnFastCopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.12/shutil.py\u001b[0m in \u001b[0;36m_fastcopy_sendfile\u001b[0;34m(fsrc, fdst)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msendfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;31m# ...in oder to have a more informative exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ---------- Main Cleaning Loop ----------\n",
    "# For each condition (day/night/rain):\n",
    "#   1. Copy ALL frames from Extracted_Frames â†’ kept_frames/{condition}/\n",
    "#   2. Check darkness â†’ move failures to rejected_frames/{condition}/\n",
    "#   3. Check blur â†’ move failures to rejected_frames/{condition}/\n",
    "#   4. Check near-duplicates (consecutive) â†’ move duplicates to rejected_frames/{condition}/\n",
    "#\n",
    "# ORDER MATTERS: We check darkness first (cheapest), then blur,\n",
    "# then duplicates (most expensive â€” requires hashing every remaining image).\n",
    "\n",
    "import time\n",
    "\n",
    "# Stats tracking\n",
    "stats = {c: {\"total\": 0, \"dark\": 0, \"blur\": 0, \"dup\": 0, \"kept\": 0} for c in CONDITIONS}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for condition, cfg in CONDITIONS.items():\n",
    "    print(f\"\\n{'='*55}\")\n",
    "    print(f\"  Processing: {condition.upper()}\")\n",
    "    print(f\"  Blur threshold: {cfg['blur_thresh']}  |  Dark threshold: {cfg['dark_thresh']}\")\n",
    "    print(f\"{'='*55}\")\n",
    "    \n",
    "    prefix = cfg[\"prefix\"]\n",
    "    blur_thresh = cfg[\"blur_thresh\"]\n",
    "    dark_thresh = cfg[\"dark_thresh\"]\n",
    "    \n",
    "    kept_dir = KEPT_DIR / condition\n",
    "    reject_dir = REJECT_DIR / condition\n",
    "    \n",
    "    # Step 1: Gather all matching frames from source\n",
    "    # Sort by name so consecutive frames are adjacent (important for duplicate detection)\n",
    "    #\n",
    "    # Day files are \"rabat_0000.jpg\" â€” startswith(\"rabat_\") would also match\n",
    "    # \"rabat_night_\" and \"rabat_rain_\", so we explicitly exclude those.\n",
    "    exclude = cfg.get(\"exclude\", [])\n",
    "    frames = sorted([\n",
    "        f for f in SOURCE_DIR.iterdir()\n",
    "        if f.name.startswith(prefix)\n",
    "        and f.suffix.lower() in (\".jpg\", \".jpeg\", \".png\")\n",
    "        and not any(f.name.startswith(ex) for ex in exclude)\n",
    "    ])\n",
    "    \n",
    "    stats[condition][\"total\"] = len(frames)\n",
    "    print(f\"  Found {len(frames)} frames matching '{condition}' pattern\")\n",
    "    \n",
    "    if len(frames) == 0:\n",
    "        print(f\"  âš  No frames found! Check that PREFIX matches your filenames.\")\n",
    "        continue\n",
    "    \n",
    "    # Step 2: Copy all frames to kept_frames first (non-destructive)\n",
    "    print(f\"  Copying to kept_frames/{condition}/ ...\")\n",
    "    for f in frames:\n",
    "        shutil.copy2(str(f), str(kept_dir / f.name))\n",
    "    \n",
    "    # Now work exclusively inside kept_dir â€” move rejects out of it\n",
    "    kept_files = sorted(list(kept_dir.iterdir()))\n",
    "    \n",
    "    # ----- Pass 1: Darkness Filter -----\n",
    "    print(f\"  Pass 1/3: Checking darkness (threshold: mean < {dark_thresh}) ...\")\n",
    "    dark_removed = 0\n",
    "    surviving = []\n",
    "    \n",
    "    for fp in kept_files:\n",
    "        img = cv2.imread(str(fp))\n",
    "        if img is None:\n",
    "            # Corrupted/unreadable file â€” reject it\n",
    "            shutil.move(str(fp), str(reject_dir / fp.name))\n",
    "            dark_removed += 1\n",
    "            continue\n",
    "        \n",
    "        too_dark, mean_val = is_too_dark(img, dark_thresh)\n",
    "        if too_dark:\n",
    "            shutil.move(str(fp), str(reject_dir / fp.name))\n",
    "            dark_removed += 1\n",
    "        else:\n",
    "            surviving.append(fp)\n",
    "    \n",
    "    stats[condition][\"dark\"] = dark_removed\n",
    "    print(f\"    Rejected {dark_removed} dark frames. Remaining: {len(surviving)}\")\n",
    "    \n",
    "    # ----- Pass 2: Blur Filter -----\n",
    "    print(f\"  Pass 2/3: Checking blur (threshold: variance < {blur_thresh}) ...\")\n",
    "    blur_removed = 0\n",
    "    still_alive = []\n",
    "    \n",
    "    for fp in surviving:\n",
    "        img = cv2.imread(str(fp))\n",
    "        too_blurry, blur_score = is_too_blurry(img, blur_thresh)\n",
    "        if too_blurry:\n",
    "            shutil.move(str(fp), str(reject_dir / fp.name))\n",
    "            blur_removed += 1\n",
    "        else:\n",
    "            still_alive.append(fp)\n",
    "    \n",
    "    stats[condition][\"blur\"] = blur_removed\n",
    "    print(f\"    Rejected {blur_removed} blurry frames. Remaining: {len(still_alive)}\")\n",
    "    \n",
    "    # ----- Pass 3: Near-Duplicate Filter -----\n",
    "    print(f\"  Pass 3/3: Checking near-duplicates (hash distance â‰¤ {HASH_DISTANCE_THRESH}) ...\")\n",
    "    dup_removed = 0\n",
    "    \n",
    "    if len(still_alive) > 1:\n",
    "        # Compute hash for the first image\n",
    "        prev_hash = compute_phash(still_alive[0])\n",
    "        \n",
    "        for i in range(1, len(still_alive)):\n",
    "            curr_hash = compute_phash(still_alive[i])\n",
    "            \n",
    "            if are_duplicates(prev_hash, curr_hash, HASH_DISTANCE_THRESH):\n",
    "                # Current frame is too similar to previous â€” reject it\n",
    "                shutil.move(str(still_alive[i]), str(reject_dir / still_alive[i].name))\n",
    "                dup_removed += 1\n",
    "                # DON'T update prev_hash â€” keep comparing against the last KEPT frame\n",
    "            else:\n",
    "                # Different enough â€” keep it, update reference hash\n",
    "                prev_hash = curr_hash\n",
    "            \n",
    "            # Progress update\n",
    "            if i % 100 == 0:\n",
    "                print(f\"    Checked {i}/{len(still_alive)} frames...\")\n",
    "    \n",
    "    stats[condition][\"dup\"] = dup_removed\n",
    "    \n",
    "    # Count final kept\n",
    "    final_kept = len(list(kept_dir.iterdir()))\n",
    "    stats[condition][\"kept\"] = final_kept\n",
    "    \n",
    "    print(f\"    Rejected {dup_removed} near-duplicates.\")\n",
    "    print(f\"  âœ“ {condition.upper()} done: {final_kept} kept / {stats[condition]['total']} original\")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\n{'='*55}\")\n",
    "print(f\"  All conditions processed in {elapsed:.1f}s\")\n",
    "print(f\"{'='*55}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a49f1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Cleaning Summary Report ----------\n",
    "# Final check: count actual files in each folder to confirm results.\n",
    "\n",
    "print(\"\\n\" + \"=\" * 65)\n",
    "print(\"  GREENFLOW RABAT â€” FRAME CLEANING REPORT\")\n",
    "print(\"=\" * 65)\n",
    "print(f\"  {'Condition':<10} {'Start':>7} {'Dark':>6} {'Blur':>6} {'Dupes':>7} {'Kept':>6}  {'Target':>10}\")\n",
    "print(f\"  {'-'*10:<10} {'-'*7:>7} {'-'*6:>6} {'-'*6:>6} {'-'*7:>7} {'-'*6:>6}  {'-'*10:>10}\")\n",
    "\n",
    "targets = {\"day\": \"450â€“500\", \"night\": \"300â€“350\", \"rain\": \"200â€“250\"}\n",
    "total_start = 0\n",
    "total_kept = 0\n",
    "total_rejected = 0\n",
    "\n",
    "for condition in CONDITIONS:\n",
    "    s = stats[condition]\n",
    "    rejected = s[\"dark\"] + s[\"blur\"] + s[\"dup\"]\n",
    "    total_start += s[\"total\"]\n",
    "    total_kept += s[\"kept\"]\n",
    "    total_rejected += rejected\n",
    "    \n",
    "    # Verify by actually counting files on disk\n",
    "    actual_kept = len(list((KEPT_DIR / condition).iterdir()))\n",
    "    actual_rejected = len(list((REJECT_DIR / condition).iterdir()))\n",
    "    \n",
    "    status = \"âœ“\" if actual_kept == s[\"kept\"] else \"âš \"\n",
    "    \n",
    "    print(f\"  {condition.upper():<10} {s['total']:>7} {s['dark']:>6} {s['blur']:>6} {s['dup']:>7} {actual_kept:>6}  {targets[condition]:>10} {status}\")\n",
    "\n",
    "print(f\"  {'-'*10:<10} {'-'*7:>7} {'-'*6:>6} {'-'*6:>6} {'-'*7:>7} {'-'*6:>6}  {'-'*10:>10}\")\n",
    "print(f\"  {'TOTAL':<10} {total_start:>7} {'':>6} {'':>6} {'':>7} {total_kept:>6}  {'~1,000':>10}\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "# Actionable next steps\n",
    "print(f\"\\n  ðŸ“‚ Kept frames:     {KEPT_DIR}\")\n",
    "print(f\"  ðŸ“‚ Rejected frames: {REJECT_DIR}\")\n",
    "print(f\"\\n  NEXT STEPS:\")\n",
    "print(f\"  1. Browse rejected_frames/ â€” rescue any good frames back to kept_frames/\")\n",
    "print(f\"  2. Browse kept_frames/ â€” remove any remaining junk the script missed\")\n",
    "print(f\"  3. When satisfied â†’ Phase 3: Upload kept_frames/ to Roboflow\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
