{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06af9c3f",
   "metadata": {},
   "source": [
    "# GreenFlow Rabat â€” Smart Traffic Intelligence\n",
    "### Hackathon RamadnIA 2026\n",
    "\n",
    "**Objective:** Transform existing CCTV cameras into smart traffic sensors using Edge AI.\n",
    "\n",
    "**Pipeline Overview:**\n",
    "1. Extract frames from local Rabat driving footage\n",
    "2. Annotate with Roboflow Label Assist (4 classes)\n",
    "3. Train YOLO11n with small-object optimizations\n",
    "4. Export to ONNX/NCNN for Raspberry Pi 5 / Jetson\n",
    "5. Real-time RTSP inference â†’ JSON webhook â†’ n8n orchestration\n",
    "\n",
    "**Classes:** `License Plate` Â· `Car` Â· `Grand Taxi` Â· `Triporteur`\n",
    "\n",
    "**Privacy:** 100% local processing. No images leave the edge device."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c78ea0",
   "metadata": {},
   "source": [
    "## Phase 1: Environment Setup\n",
    "Installs all dependencies and verifies the hardware (CPU vs GPU).  \n",
    "Run this cell once per session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04067db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All packages installed.\n"
     ]
    }
   ],
   "source": [
    "# ---------- Install Dependencies ----------\n",
    "# We use subprocess instead of !pip to work on ANY platform\n",
    "# (local, Colab, Kaggle, Paperspace â€” no Colab-specific syntax).\n",
    "\n",
    "import subprocess, sys\n",
    "\n",
    "packages = [\n",
    "    \"ultralytics\",            # YOLO11n â€” our detection model\n",
    "    \"roboflow\",               # Dataset download + annotation API\n",
    "    \"opencv-python-headless\", # Image/video processing (headless = no GUI needed)\n",
    "    \"requests\",               # HTTP calls to n8n webhooks\n",
    "]\n",
    "\n",
    "for pkg in packages:\n",
    "    subprocess.check_call(\n",
    "        [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg],\n",
    "        stdout=subprocess.DEVNULL  # suppress noisy pip output\n",
    "    )\n",
    "\n",
    "print(\"All packages installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "746279ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "  GreenFlow Rabat â€” Environment Report\n",
      "=============================================\n",
      "  Python :  3.12.12\n",
      "  PyTorch:  2.9.0+cu128\n",
      "  CUDA   :  True\n",
      "  GPU    :  Tesla T4\n",
      "  VRAM   :  15.6 GB\n",
      "  OS     :  Linux x86_64\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "# ---------- Hardware Check ----------\n",
    "# This tells us if we have a GPU available.\n",
    "# Training on CPU = hours.  Training on GPU = minutes.\n",
    "\n",
    "import torch\n",
    "import platform\n",
    "\n",
    "print(\"=\" * 45)\n",
    "print(\"  GreenFlow Rabat â€” Environment Report\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"  Python :  {platform.python_version()}\")\n",
    "print(f\"  PyTorch:  {torch.__version__}\")\n",
    "print(f\"  CUDA   :  {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  GPU    :  {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  VRAM   :  {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"  GPU    :  None (CPU mode)\")\n",
    "    print(\"  Tip    :  Connect Colab GPU for training (Phase 5)\")\n",
    "\n",
    "print(f\"  OS     :  {platform.system()} {platform.machine()}\")\n",
    "print(\"=\" * 45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47941747",
   "metadata": {},
   "source": [
    "## Phase 2: Frame Extraction\n",
    "Extract 1 frame every 5 seconds from the Rabat driving video.  \n",
    "Output: ~480 JPEG images saved to `data/frames/` for Roboflow annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "129c1f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "Video found: (1457 MB)\n",
      "Prefix: rabat_night_XXXX.jpg\n"
     ]
    }
   ],
   "source": [
    "# ---------- Configuration ----------\n",
    "# We mount Google Drive to access the video AND save frames there.\n",
    "# Everything stays on Drive â€” permanent, survives session restarts.\n",
    "#\n",
    "# WORKFLOW: For each video, change VIDEO_PATH and PREFIX, then re-run cells 6+7.\n",
    "#   Run 1: day    â†’ \"rabat_day_0000.jpg\"   (already done with 523 frames)\n",
    "#   Run 2: night  â†’ \"rabat_night_0000.jpg\"\n",
    "#   Run 3: rain   â†’ \"rabat_rain_0000.jpg\"\n",
    "#   Run 4: dusk   â†’ \"rabat_dusk_0000.jpg\"\n",
    "\n",
    "from pathlib import Path\n",
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive (a browser popup will ask for permission once)\n",
    "drive.mount(\"/content/drive\")\n",
    "\n",
    "# ---- CHANGE THESE TWO FOR EACH VIDEO ----\n",
    "VIDEO_PATH = \"/content/drive/MyDrive/GreenFlow-Rabat/YTDown.com_YouTube_Rabat-4K-Night-Drive-Driving-Downtown-Re_Media_aFtBUlb9yj8_001_1080p.mp4\"\n",
    "PREFIX = \"rabat_night\"  # Change per video: \"rabat_day\", \"rabat_night\", \"rabat_rain\", \"rabat_dusk\"\n",
    "# ------------------------------------------\n",
    "\n",
    "# Extracted frames saved to your existing Drive folder (permanent storage)\n",
    "OUTPUT_DIR = Path(\"/content/drive/MyDrive/GreenFlow-Rabat/Extracted_Frames\")\n",
    "INTERVAL_SEC = 5  # Extract 1 frame every N seconds\n",
    "\n",
    "# Sanity check\n",
    "import os\n",
    "if os.path.exists(VIDEO_PATH):\n",
    "    size_mb = os.path.getsize(VIDEO_PATH) / 1e6\n",
    "    print(f\"Video found: ({size_mb:.0f} MB)\")\n",
    "    print(f\"Prefix: {PREFIX}_XXXX.jpg\")\n",
    "else:\n",
    "    print(f\"Video NOT found at: {VIDEO_PATH}\")\n",
    "    print(\"Check the filename in your Drive folder and update VIDEO_PATH above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb6f3baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video info: 30.0 FPS | 95,040 total frames | 52.9 min\n",
      "Strategy:   1 frame every 5s = every 149 frames\n",
      "Expected:   ~637 frames to extract\n",
      "\n",
      "  Saved 50 frames...\n",
      "  Saved 100 frames...\n",
      "  Saved 150 frames...\n",
      "  Saved 200 frames...\n",
      "  Saved 250 frames...\n",
      "  Saved 300 frames...\n",
      "  Saved 350 frames...\n",
      "  Saved 400 frames...\n",
      "  Saved 450 frames...\n",
      "  Saved 500 frames...\n",
      "  Saved 550 frames...\n",
      "  Saved 600 frames...\n",
      "\n",
      "Done! Extracted 638 frames â†’ /content/drive/MyDrive/GreenFlow-Rabat/Extracted_Frames/\n"
     ]
    }
   ],
   "source": [
    "# ---------- Extract Frames ----------\n",
    "import cv2\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "\n",
    "# Read video metadata\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)                    # Frames per second of the video\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # Total number of frames\n",
    "duration_min = total_frames / fps / 60              # Video length in minutes\n",
    "frame_step = int(fps * INTERVAL_SEC)                # How many frames to skip between captures\n",
    "\n",
    "print(f\"Video info: {fps:.1f} FPS | {total_frames:,} total frames | {duration_min:.1f} min\")\n",
    "print(f\"Strategy:   1 frame every {INTERVAL_SEC}s = every {frame_step} frames\")\n",
    "print(f\"Expected:   ~{total_frames // frame_step} frames to extract\\n\")\n",
    "\n",
    "# Main extraction loop\n",
    "saved = 0\n",
    "frame_idx = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()       # Read one frame from the video\n",
    "    if not ret:                   # ret is False when video ends\n",
    "        break\n",
    "    \n",
    "    if frame_idx % frame_step == 0:  # Only save every Nth frame\n",
    "        # Mask watermark \"STREET.MA\" at bottom-right corner\n",
    "        h, w = frame.shape[:2]\n",
    "        frame[h-120:h, w-450:w] = 0  # Black out a 450x120 px rectangle\n",
    "        \n",
    "        filename = OUTPUT_DIR / f\"{PREFIX}_{saved:04d}.jpg\"\n",
    "        cv2.imwrite(str(filename), frame)\n",
    "        saved += 1\n",
    "        \n",
    "        # Progress update every 50 saved frames\n",
    "        if saved % 50 == 0:\n",
    "            print(f\"  Saved {saved} frames...\")\n",
    "    \n",
    "    frame_idx += 1\n",
    "\n",
    "cap.release()  # Always release the video capture when done\n",
    "\n",
    "print(f\"\\nDone! Extracted {saved} frames â†’ {OUTPUT_DIR}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffad88b",
   "metadata": {},
   "source": [
    "## Phase 2.5: Automated Frame Cleaning\n",
    "Smart filtering to remove near-duplicates, severely blurred, and pitch-black frames.  \n",
    "**Safety rule:** Nothing is deleted â€” rejected frames are *moved* to a `rejected_frames/` folder for manual review.\n",
    "\n",
    "| Filter | Method | Day | Night | Rain |\n",
    "|--------|--------|-----|-------|------|\n",
    "| Near-duplicates | Perceptual hash (hamming dist) | Main filter | Active | Active |\n",
    "| Motion blur | Laplacian variance | Strict (50) | Lenient (15) | Moderate (25) |\n",
    "| Extreme darkness | Mean pixel intensity | Rarely triggers | Main filter | Rarely triggers |\n",
    "\n",
    "**Targets:** 522â†’~480 Day Â· 637â†’~320 Night Â· 300â†’~230 Rain â‰ˆ **~1,000 clean frames**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bd09327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imagehash installed âœ“\n"
     ]
    }
   ],
   "source": [
    "# ---------- Install imagehash (one-time) ----------\n",
    "# imagehash provides perceptual hashing â€” it converts images into\n",
    "# compact \"fingerprints\" so we can detect near-duplicates by comparing\n",
    "# fingerprints instead of pixel-by-pixel (which is too slow and fragile).\n",
    "\n",
    "import subprocess, sys\n",
    "\n",
    "subprocess.check_call(\n",
    "    [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"imagehash\"],\n",
    "    stdout=subprocess.DEVNULL\n",
    ")\n",
    "print(\"imagehash installed âœ“\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b837ad6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Source:   /content/drive/MyDrive/GreenFlow-Rabat/Extracted_Frames\n",
      "Kept:     /content/drive/MyDrive/GreenFlow-Rabat/kept_frames\n",
      "Rejected: /content/drive/MyDrive/GreenFlow-Rabat/rejected_frames\n",
      "\n",
      "Subfolders created: ['day', 'night', 'rain']\n",
      "Hash distance threshold: 4\n",
      "  day    â†’ blur < 50  |  dark < 20\n",
      "  night  â†’ blur < 15  |  dark < 30\n",
      "  rain   â†’ blur < 25  |  dark < 20\n"
     ]
    }
   ],
   "source": [
    "# ---------- Configuration & Folder Setup ----------\n",
    "# Source: your existing Extracted_Frames folder on Drive\n",
    "# Output: two NEW sibling folders â€” kept_frames/ and rejected_frames/\n",
    "# Each mirrors the Day/Night/Rain subfolder structure.\n",
    "\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\")\n",
    "\n",
    "# ---- Paths (adjust if your folder names differ) ----\n",
    "BASE_DIR = Path(\"/content/drive/MyDrive/GreenFlow-Rabat\")\n",
    "SOURCE_DIR = BASE_DIR / \"Extracted_Frames\"     # Where all 1,459 frames live now\n",
    "KEPT_DIR   = BASE_DIR / \"kept_frames\"           # Clean frames go here â†’ Roboflow\n",
    "REJECT_DIR = BASE_DIR / \"rejected_frames\"       # Rejected frames go here â†’ manual review\n",
    "\n",
    "# Subfolder mapping: prefix pattern â†’ condition label\n",
    "# This tells the script which threshold profile to use for each image.\n",
    "#\n",
    "# IMPORTANT: Day frames are named \"rabat_0000.jpg\" (no 'day' keyword),\n",
    "# while night/rain have explicit prefixes (\"rabat_night_\", \"rabat_rain_\").\n",
    "# We use \"exclude\" to prevent the day matcher from grabbing night/rain files.\n",
    "CONDITIONS = {\n",
    "    \"day\":   {\"prefix\": \"rabat_\",      \"exclude\": [\"rabat_night\", \"rabat_rain\"], \"blur_thresh\": 50, \"dark_thresh\": 20},\n",
    "    \"night\": {\"prefix\": \"rabat_night\",  \"exclude\": [],                             \"blur_thresh\": 15, \"dark_thresh\": 30},\n",
    "    \"rain\":  {\"prefix\": \"rabat_rain\",   \"exclude\": [],                             \"blur_thresh\": 25, \"dark_thresh\": 20},\n",
    "}\n",
    "\n",
    "# Similarity threshold: perceptual hash hamming distance.\n",
    "# Two images with hash distance <= this value are considered duplicates.\n",
    "# Lower = stricter (only very similar rejected). Higher = more aggressive.\n",
    "HASH_DISTANCE_THRESH = 4   # ~94% similarity on a 64-bit hash\n",
    "\n",
    "# Create output folders\n",
    "for condition in CONDITIONS:\n",
    "    (KEPT_DIR / condition).mkdir(parents=True, exist_ok=True)\n",
    "    (REJECT_DIR / condition).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Source:   {SOURCE_DIR}\")\n",
    "print(f\"Kept:     {KEPT_DIR}\")\n",
    "print(f\"Rejected: {REJECT_DIR}\")\n",
    "print(f\"\\nSubfolders created: {list(CONDITIONS.keys())}\")\n",
    "print(f\"Hash distance threshold: {HASH_DISTANCE_THRESH}\")\n",
    "for c, cfg in CONDITIONS.items():\n",
    "    print(f\"  {c:6s} â†’ blur < {cfg['blur_thresh']}  |  dark < {cfg['dark_thresh']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a202bdf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering functions loaded âœ“\n",
      "  compute_blur_score(img)   â†’ float (higher = sharper)\n",
      "  is_too_blurry(img, thr)   â†’ (bool, score)\n",
      "  is_too_dark(img, thr)     â†’ (bool, mean_intensity)\n",
      "  compute_phash(path)       â†’ imagehash object\n",
      "  are_duplicates(h1,h2,thr) â†’ bool\n"
     ]
    }
   ],
   "source": [
    "# ---------- Filtering Functions ----------\n",
    "# Each function returns True if the image FAILS the quality check\n",
    "# (i.e., should be rejected).\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imagehash\n",
    "from PIL import Image\n",
    "\n",
    "def compute_blur_score(img_bgr):\n",
    "    \"\"\"\n",
    "    Variance of the Laplacian â€” the classic blur detector.\n",
    "    \n",
    "    HOW IT WORKS:\n",
    "    - The Laplacian operator detects edges (rapid intensity changes).\n",
    "    - A sharp image has many strong edges â†’ high variance.\n",
    "    - A blurry image has few/weak edges â†’ low variance.\n",
    "    \n",
    "    Returns a float: higher = sharper. Typical ranges:\n",
    "      - Very sharp:  200+\n",
    "      - Acceptable:  50â€“200\n",
    "      - Blurry:      < 50  (day)  /  < 15 (night)\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    laplacian = cv2.Laplacian(gray, cv2.CV_64F)  # 2nd derivative of intensity\n",
    "    return laplacian.var()                         # Variance = spread of edge strengths\n",
    "\n",
    "\n",
    "def is_too_blurry(img_bgr, threshold):\n",
    "    \"\"\"Check if frame is too blurry for the given condition's threshold.\"\"\"\n",
    "    score = compute_blur_score(img_bgr)\n",
    "    return score < threshold, score\n",
    "\n",
    "\n",
    "def is_too_dark(img_bgr, threshold):\n",
    "    \"\"\"\n",
    "    Check if frame is too dark to contain useful information.\n",
    "    \n",
    "    HOW IT WORKS:\n",
    "    - Convert to grayscale (single channel, 0=black, 255=white).\n",
    "    - Compute the mean pixel value across the entire image.\n",
    "    - If the average is below the threshold, the frame is essentially\n",
    "      pitch-black or so dark that no vehicle features are distinguishable.\n",
    "    \n",
    "    Night frames naturally have lower means (~40â€“80), so the threshold\n",
    "    is set per-condition to avoid false rejections.\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    mean_intensity = np.mean(gray)\n",
    "    return mean_intensity < threshold, mean_intensity\n",
    "\n",
    "\n",
    "def compute_phash(img_path):\n",
    "    \"\"\"\n",
    "    Compute a perceptual hash (pHash) for an image.\n",
    "    \n",
    "    HOW IT WORKS:\n",
    "    - Resize image to 32x32, convert to grayscale.\n",
    "    - Apply DCT (Discrete Cosine Transform) â€” like a 2D frequency analysis.\n",
    "    - Keep only the low-frequency components (overall structure, not detail).\n",
    "    - Threshold to produce a 64-bit binary hash.\n",
    "    \n",
    "    Two visually similar images produce nearly identical hashes,\n",
    "    even if they differ in brightness, compression, or minor shifts.\n",
    "    \n",
    "    Hamming distance = number of bits that differ between two hashes.\n",
    "    - 0 = identical images\n",
    "    - 1-4 = near-duplicates (traffic jam consecutive frames)\n",
    "    - 10+ = clearly different scenes\n",
    "    \"\"\"\n",
    "    pil_img = Image.open(str(img_path))\n",
    "    return imagehash.phash(pil_img)\n",
    "\n",
    "\n",
    "def are_duplicates(hash1, hash2, threshold):\n",
    "    \"\"\"\n",
    "    Compare two perceptual hashes.\n",
    "    The '-' operator gives the Hamming distance (number of differing bits).\n",
    "    \"\"\"\n",
    "    return (hash1 - hash2) <= threshold\n",
    "\n",
    "print(\"Filtering functions loaded âœ“\")\n",
    "print(f\"  compute_blur_score(img)   â†’ float (higher = sharper)\")\n",
    "print(f\"  is_too_blurry(img, thr)   â†’ (bool, score)\")\n",
    "print(f\"  is_too_dark(img, thr)     â†’ (bool, mean_intensity)\")\n",
    "print(f\"  compute_phash(path)       â†’ imagehash object\")\n",
    "print(f\"  are_duplicates(h1,h2,thr) â†’ bool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "422b3e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================================\n",
      "  Processing: DAY\n",
      "  Blur threshold: 50  |  Dark threshold: 20\n",
      "=======================================================\n",
      "  Found 523 frames matching 'day' pattern\n",
      "  Copying to kept_frames/day/ ...\n",
      "  Pass 1/3: Checking darkness (threshold: mean < 20) ...\n",
      "    Rejected 0 dark frames. Remaining: 523\n",
      "  Pass 2/3: Checking blur (threshold: variance < 50) ...\n",
      "    Rejected 1 blurry frames. Remaining: 522\n",
      "  Pass 3/3: Checking near-duplicates (hash distance â‰¤ 4) ...\n",
      "    Checked 100/522 frames...\n",
      "    Checked 200/522 frames...\n",
      "    Checked 300/522 frames...\n",
      "    Checked 400/522 frames...\n",
      "    Checked 500/522 frames...\n",
      "    Rejected 1 near-duplicates.\n",
      "  âœ“ DAY done: 521 kept / 523 original\n",
      "\n",
      "=======================================================\n",
      "  Processing: NIGHT\n",
      "  Blur threshold: 15  |  Dark threshold: 30\n",
      "=======================================================\n",
      "  Found 638 frames matching 'night' pattern\n",
      "  Copying to kept_frames/night/ ...\n",
      "  Pass 1/3: Checking darkness (threshold: mean < 30) ...\n",
      "    Rejected 57 dark frames. Remaining: 580\n",
      "  Pass 2/3: Checking blur (threshold: variance < 15) ...\n",
      "    Rejected 4 blurry frames. Remaining: 576\n",
      "  Pass 3/3: Checking near-duplicates (hash distance â‰¤ 4) ...\n",
      "    Checked 100/576 frames...\n",
      "    Checked 200/576 frames...\n",
      "    Checked 300/576 frames...\n",
      "    Checked 400/576 frames...\n",
      "    Checked 500/576 frames...\n",
      "    Rejected 1 near-duplicates.\n",
      "  âœ“ NIGHT done: 575 kept / 638 original\n",
      "\n",
      "=======================================================\n",
      "  Processing: RAIN\n",
      "  Blur threshold: 25  |  Dark threshold: 20\n",
      "=======================================================\n",
      "  Found 293 frames matching 'rain' pattern\n",
      "  Copying to kept_frames/rain/ ...\n",
      "  Pass 1/3: Checking darkness (threshold: mean < 20) ...\n",
      "    Rejected 0 dark frames. Remaining: 293\n",
      "  Pass 2/3: Checking blur (threshold: variance < 25) ...\n",
      "    Rejected 1 blurry frames. Remaining: 292\n",
      "  Pass 3/3: Checking near-duplicates (hash distance â‰¤ 4) ...\n",
      "    Checked 100/292 frames...\n",
      "    Checked 200/292 frames...\n",
      "    Rejected 59 near-duplicates.\n",
      "  âœ“ RAIN done: 233 kept / 293 original\n",
      "\n",
      "=======================================================\n",
      "  All conditions processed in 584.9s\n",
      "=======================================================\n"
     ]
    }
   ],
   "source": [
    "# ---------- Main Cleaning Loop ----------\n",
    "# For each condition (day/night/rain):\n",
    "#   1. Copy ALL frames from Extracted_Frames â†’ kept_frames/{condition}/\n",
    "#   2. Check darkness â†’ move failures to rejected_frames/{condition}/\n",
    "#   3. Check blur â†’ move failures to rejected_frames/{condition}/\n",
    "#   4. Check near-duplicates (consecutive) â†’ move duplicates to rejected_frames/{condition}/\n",
    "#\n",
    "# ORDER MATTERS: We check darkness first (cheapest), then blur,\n",
    "# then duplicates (most expensive â€” requires hashing every remaining image).\n",
    "\n",
    "import time\n",
    "\n",
    "# Stats tracking\n",
    "stats = {c: {\"total\": 0, \"dark\": 0, \"blur\": 0, \"dup\": 0, \"kept\": 0} for c in CONDITIONS}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for condition, cfg in CONDITIONS.items():\n",
    "    print(f\"\\n{'='*55}\")\n",
    "    print(f\"  Processing: {condition.upper()}\")\n",
    "    print(f\"  Blur threshold: {cfg['blur_thresh']}  |  Dark threshold: {cfg['dark_thresh']}\")\n",
    "    print(f\"{'='*55}\")\n",
    "    \n",
    "    prefix = cfg[\"prefix\"]\n",
    "    blur_thresh = cfg[\"blur_thresh\"]\n",
    "    dark_thresh = cfg[\"dark_thresh\"]\n",
    "    \n",
    "    kept_dir = KEPT_DIR / condition\n",
    "    reject_dir = REJECT_DIR / condition\n",
    "     \n",
    "    # Step 1: Gather all matching frames from source\n",
    "    # Sort by name so consecutive frames are adjacent (important for duplicate detection)\n",
    "    #\n",
    "    # Day files are \"rabat_0000.jpg\" â€” startswith(\"rabat_\") would also match\n",
    "    # \"rabat_night_\" and \"rabat_rain_\", so we explicitly exclude those.\n",
    "    exclude = cfg.get(\"exclude\", [])\n",
    "    frames = sorted([\n",
    "        f for f in SOURCE_DIR.iterdir()\n",
    "        if f.name.startswith(prefix)\n",
    "        and f.suffix.lower() in (\".jpg\", \".jpeg\", \".png\")\n",
    "        and not any(f.name.startswith(ex) for ex in exclude)\n",
    "    ])\n",
    "    \n",
    "    stats[condition][\"total\"] = len(frames)\n",
    "    print(f\"  Found {len(frames)} frames matching '{condition}' pattern\")\n",
    "    \n",
    "    if len(frames) == 0:\n",
    "        print(f\"  âš  No frames found! Check that PREFIX matches your filenames.\")\n",
    "        continue\n",
    "    \n",
    "    # Step 2: Copy all frames to kept_frames first (non-destructive)\n",
    "    print(f\"  Copying to kept_frames/{condition}/ ...\")\n",
    "    for f in frames:\n",
    "        shutil.copy2(str(f), str(kept_dir / f.name))\n",
    "    \n",
    "    # Now work exclusively inside kept_dir â€” move rejects out of it\n",
    "    kept_files = sorted(list(kept_dir.iterdir()))\n",
    "    \n",
    "    # ----- Pass 1: Darkness Filter -----\n",
    "    print(f\"  Pass 1/3: Checking darkness (threshold: mean < {dark_thresh}) ...\")\n",
    "    dark_removed = 0\n",
    "    surviving = []\n",
    "    \n",
    "    for fp in kept_files:\n",
    "        img = cv2.imread(str(fp))\n",
    "        if img is None:\n",
    "            # Corrupted/unreadable file â€” reject it\n",
    "            shutil.move(str(fp), str(reject_dir / fp.name))\n",
    "            dark_removed += 1\n",
    "            continue\n",
    "        \n",
    "        too_dark, mean_val = is_too_dark(img, dark_thresh)\n",
    "        if too_dark:\n",
    "            shutil.move(str(fp), str(reject_dir / fp.name))\n",
    "            dark_removed += 1\n",
    "        else:\n",
    "            surviving.append(fp)\n",
    "    \n",
    "    stats[condition][\"dark\"] = dark_removed\n",
    "    print(f\"    Rejected {dark_removed} dark frames. Remaining: {len(surviving)}\")\n",
    "    \n",
    "    # ----- Pass 2: Blur Filter -----\n",
    "    print(f\"  Pass 2/3: Checking blur (threshold: variance < {blur_thresh}) ...\")\n",
    "    blur_removed = 0\n",
    "    still_alive = []\n",
    "    \n",
    "    for fp in surviving:\n",
    "        img = cv2.imread(str(fp))\n",
    "        too_blurry, blur_score = is_too_blurry(img, blur_thresh)\n",
    "        if too_blurry:\n",
    "            shutil.move(str(fp), str(reject_dir / fp.name))\n",
    "            blur_removed += 1\n",
    "        else:\n",
    "            still_alive.append(fp)\n",
    "    \n",
    "    stats[condition][\"blur\"] = blur_removed\n",
    "    print(f\"    Rejected {blur_removed} blurry frames. Remaining: {len(still_alive)}\")\n",
    "    \n",
    "    # ----- Pass 3: Near-Duplicate Filter -----\n",
    "    print(f\"  Pass 3/3: Checking near-duplicates (hash distance â‰¤ {HASH_DISTANCE_THRESH}) ...\")\n",
    "    dup_removed = 0\n",
    "    \n",
    "    if len(still_alive) > 1:\n",
    "        # Compute hash for the first image\n",
    "        prev_hash = compute_phash(still_alive[0])\n",
    "        \n",
    "        for i in range(1, len(still_alive)):\n",
    "            curr_hash = compute_phash(still_alive[i])\n",
    "            \n",
    "            if are_duplicates(prev_hash, curr_hash, HASH_DISTANCE_THRESH):\n",
    "                # Current frame is too similar to previous â€” reject it\n",
    "                shutil.move(str(still_alive[i]), str(reject_dir / still_alive[i].name))\n",
    "                dup_removed += 1\n",
    "                # DON'T update prev_hash â€” keep comparing against the last KEPT frame\n",
    "            else:\n",
    "                # Different enough â€” keep it, update reference hash\n",
    "                prev_hash = curr_hash\n",
    "            \n",
    "            # Progress update\n",
    "            if i % 100 == 0:\n",
    "                print(f\"    Checked {i}/{len(still_alive)} frames...\")\n",
    "    \n",
    "    stats[condition][\"dup\"] = dup_removed\n",
    "    \n",
    "    # Count final kept\n",
    "    final_kept = len(list(kept_dir.iterdir()))\n",
    "    stats[condition][\"kept\"] = final_kept\n",
    "    \n",
    "    print(f\"    Rejected {dup_removed} near-duplicates.\")\n",
    "    print(f\"  âœ“ {condition.upper()} done: {final_kept} kept / {stats[condition]['total']} original\")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\n{'='*55}\")\n",
    "print(f\"  All conditions processed in {elapsed:.1f}s\")\n",
    "print(f\"{'='*55}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a49f1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "  GREENFLOW RABAT â€” FRAME CLEANING REPORT\n",
      "=================================================================\n",
      "  Condition    Start   Dark   Blur   Dupes   Kept      Target\n",
      "  ---------- ------- ------ ------ ------- ------  ----------\n",
      "  DAY            523      0      1       1    521     450â€“500 âœ“\n",
      "  NIGHT          638     57      4       1    575     300â€“350 âœ“\n",
      "  RAIN           293      0      1      59    233     200â€“250 âœ“\n",
      "  ---------- ------- ------ ------ ------- ------  ----------\n",
      "  TOTAL         1454                         1329      ~1,000\n",
      "=================================================================\n",
      "\n",
      "  ðŸ“‚ Kept frames:     /content/drive/MyDrive/GreenFlow-Rabat/kept_frames\n",
      "  ðŸ“‚ Rejected frames: /content/drive/MyDrive/GreenFlow-Rabat/rejected_frames\n",
      "\n",
      "  NEXT STEPS:\n",
      "  1. Browse rejected_frames/ â€” rescue any good frames back to kept_frames/\n",
      "  2. Browse kept_frames/ â€” remove any remaining junk the script missed\n",
      "  3. When satisfied â†’ Phase 3: Upload kept_frames/ to Roboflow\n"
     ]
    }
   ],
   "source": [
    "# ---------- Cleaning Summary Report ----------\n",
    "# Final check: count actual files in each folder to confirm results.\n",
    "\n",
    "print(\"\\n\" + \"=\" * 65)\n",
    "print(\"  GREENFLOW RABAT â€” FRAME CLEANING REPORT\")\n",
    "print(\"=\" * 65)\n",
    "print(f\"  {'Condition':<10} {'Start':>7} {'Dark':>6} {'Blur':>6} {'Dupes':>7} {'Kept':>6}  {'Target':>10}\")\n",
    "print(f\"  {'-'*10:<10} {'-'*7:>7} {'-'*6:>6} {'-'*6:>6} {'-'*7:>7} {'-'*6:>6}  {'-'*10:>10}\")\n",
    "\n",
    "targets = {\"day\": \"450â€“500\", \"night\": \"300â€“350\", \"rain\": \"200â€“250\"}\n",
    "total_start = 0\n",
    "total_kept = 0\n",
    "total_rejected = 0\n",
    "\n",
    "for condition in CONDITIONS:\n",
    "    s = stats[condition]\n",
    "    rejected = s[\"dark\"] + s[\"blur\"] + s[\"dup\"]\n",
    "    total_start += s[\"total\"]\n",
    "    total_kept += s[\"kept\"]\n",
    "    total_rejected += rejected\n",
    "    \n",
    "    # Verify by actually counting files on disk\n",
    "    actual_kept = len(list((KEPT_DIR / condition).iterdir()))\n",
    "    actual_rejected = len(list((REJECT_DIR / condition).iterdir()))\n",
    "    \n",
    "    status = \"âœ“\" if actual_kept == s[\"kept\"] else \"âš \"\n",
    "    \n",
    "    print(f\"  {condition.upper():<10} {s['total']:>7} {s['dark']:>6} {s['blur']:>6} {s['dup']:>7} {actual_kept:>6}  {targets[condition]:>10} {status}\")\n",
    "\n",
    "print(f\"  {'-'*10:<10} {'-'*7:>7} {'-'*6:>6} {'-'*6:>6} {'-'*7:>7} {'-'*6:>6}  {'-'*10:>10}\")\n",
    "print(f\"  {'TOTAL':<10} {total_start:>7} {'':>6} {'':>6} {'':>7} {total_kept:>6}  {'~1,000':>10}\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "# Actionable next steps\n",
    "print(f\"\\n  ðŸ“‚ Kept frames:     {KEPT_DIR}\")\n",
    "print(f\"  ðŸ“‚ Rejected frames: {REJECT_DIR}\")\n",
    "print(f\"\\n  NEXT STEPS:\")\n",
    "print(f\"  1. Browse rejected_frames/ â€” rescue any good frames back to kept_frames/\")\n",
    "print(f\"  2. Browse kept_frames/ â€” remove any remaining junk the script missed\")\n",
    "print(f\"  3. When satisfied â†’ Phase 3: Upload kept_frames/ to Roboflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff23732",
   "metadata": {},
   "source": [
    "## Phase 3: Dataset Fusion (80/20 Hybrid)\n",
    "Merge two data sources into one unified training set:\n",
    "\n",
    "| Source | Content | Status | Role |\n",
    "|--------|---------|--------|------|\n",
    "| `CCTV.v9i.yolov8/` | ~5,000 global CCTV images | Pre-annotated (YOLO format) | 80% foundation |\n",
    "| `kept_frames/` | ~1,000 local Moroccan frames | **Not annotated** | 20% specialization |\n",
    "\n",
    "**Strategy:** Upload both to Roboflow â†’ annotate local frames with Label Assist â†’ export unified YOLO dataset.  \n",
    "**Rule:** Everything stays in the cloud (Drive + Roboflow). No local merge. No class-index conflicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ba0a350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "============================================================\n",
      "  CCTV.v9i.yolov8 â€” Folder Structure\n",
      "============================================================\n",
      "  ðŸ“„ README.dataset.txt\n",
      "  ðŸ“„ README.roboflow.txt\n",
      "  ðŸ“„ data.yaml\n",
      "  ðŸ“ test/  (108 files)\n",
      "      ðŸ“ images/  (54 files)\n",
      "      ðŸ“ labels/  (54 files)\n",
      "  ðŸ“ train/  (8740 files)\n",
      "      ðŸ“ images/  (4370 files)\n",
      "      ðŸ“ labels/  (4370 files)\n",
      "  ðŸ“ valid/  (1216 files)\n",
      "      ðŸ“ images/  (608 files)\n",
      "      ðŸ“ labels/  (608 files)\n",
      "\n",
      "============================================================\n",
      "  data.yaml Contents\n",
      "============================================================\n",
      "  Number of classes (nc): 7\n",
      "  Class names:\n",
      "    0: ambulan\n",
      "    1: bis\n",
      "    2: mobil\n",
      "    3: motor\n",
      "    4: pemadam-kebakaran\n",
      "    5: polisi\n",
      "    6: truk\n",
      "\n",
      "  Train path: ../train/images\n",
      "  Valid path: ../valid/images\n",
      "  Test path:  ../test/images\n",
      "\n",
      "============================================================\n",
      "  Image Counts per Split\n",
      "============================================================\n",
      "  train :  4370 images\n",
      "  valid :   608 images\n",
      "  test  :    54 images\n",
      "\n",
      "============================================================\n",
      "  Sample Label (first .txt in train/labels/)\n",
      "============================================================\n",
      "  File: 008CY5SRHBLM_jpg.rf.a1a98f0c14a7e0a12dc1599d84591ef0.txt\n",
      "    class=0  bbox=0.496875 0.4921875 0.8578125 0.5671875\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ---------- Step 3.1: Inspect Global Dataset Structure ----------\n",
    "# Before merging, we MUST understand how CCTV.v9i.yolov8 is organized:\n",
    "#   - Folder layout (train/valid/test splits?)\n",
    "#   - data.yaml (class names, class IDs, number of images)\n",
    "#   - Sample label file (to verify annotation format)\n",
    "#\n",
    "# This tells us if there are class-index conflicts to resolve.\n",
    "\n",
    "from pathlib import Path\n",
    "from google.colab import drive\n",
    "import yaml\n",
    "\n",
    "drive.mount(\"/content/drive\")\n",
    "\n",
    "GLOBAL_DIR = Path(\"/content/drive/MyDrive/GreenFlow-Rabat/CCTV.v9i.yolov8\")\n",
    "\n",
    "# ---- 1. Folder tree (2 levels deep) ----\n",
    "print(\"=\" * 60)\n",
    "print(\"  CCTV.v9i.yolov8 â€” Folder Structure\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def print_tree(path, prefix=\"\", max_depth=2, _depth=0):\n",
    "    \"\"\"Print a directory tree, limited to max_depth levels.\"\"\"\n",
    "    if _depth >= max_depth:\n",
    "        return\n",
    "    try:\n",
    "        entries = sorted(path.iterdir())\n",
    "    except PermissionError:\n",
    "        return\n",
    "    \n",
    "    dirs = [e for e in entries if e.is_dir()]\n",
    "    files = [e for e in entries if e.is_file()]\n",
    "    \n",
    "    # Show files (limit to 5 per folder to avoid spam)\n",
    "    for f in files[:5]:\n",
    "        print(f\"{prefix}  ðŸ“„ {f.name}\")\n",
    "    if len(files) > 5:\n",
    "        print(f\"{prefix}  ... and {len(files) - 5} more files\")\n",
    "    \n",
    "    # Recurse into subdirectories\n",
    "    for d in dirs:\n",
    "        file_count = len(list(d.rglob(\"*.*\")))\n",
    "        print(f\"{prefix}  ðŸ“ {d.name}/  ({file_count} files)\")\n",
    "        print_tree(d, prefix + \"    \", max_depth, _depth + 1)\n",
    "\n",
    "print_tree(GLOBAL_DIR)\n",
    "\n",
    "# ---- 2. Parse data.yaml ----\n",
    "yaml_path = GLOBAL_DIR / \"data.yaml\"\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"  data.yaml Contents\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if yaml_path.exists():\n",
    "    with open(yaml_path, \"r\") as f:\n",
    "        data_cfg = yaml.safe_load(f)\n",
    "    \n",
    "    print(f\"  Number of classes (nc): {data_cfg.get('nc', 'NOT FOUND')}\")\n",
    "    print(f\"  Class names:\")\n",
    "    names = data_cfg.get(\"names\", [])\n",
    "    if isinstance(names, dict):\n",
    "        for idx, name in names.items():\n",
    "            print(f\"    {idx}: {name}\")\n",
    "    elif isinstance(names, list):\n",
    "        for idx, name in enumerate(names):\n",
    "            print(f\"    {idx}: {name}\")\n",
    "    \n",
    "    print(f\"\\n  Train path: {data_cfg.get('train', 'NOT FOUND')}\")\n",
    "    print(f\"  Valid path: {data_cfg.get('val', 'NOT FOUND')}\")\n",
    "    print(f\"  Test path:  {data_cfg.get('test', 'NOT FOUND')}\")\n",
    "else:\n",
    "    print(\"  âš  data.yaml NOT FOUND â€” check folder name\")\n",
    "\n",
    "# ---- 3. Count images per split ----\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"  Image Counts per Split\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for split in [\"train\", \"valid\", \"test\"]:\n",
    "    img_dir = GLOBAL_DIR / split / \"images\"\n",
    "    if img_dir.exists():\n",
    "        count = len([f for f in img_dir.iterdir() if f.suffix.lower() in (\".jpg\", \".jpeg\", \".png\")])\n",
    "        print(f\"  {split:6s}: {count:>5} images\")\n",
    "    else:\n",
    "        print(f\"  {split:6s}: folder not found\")\n",
    "\n",
    "# ---- 4. Sample a label file to verify format ----\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"  Sample Label (first .txt in train/labels/)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "label_dir = GLOBAL_DIR / \"train\" / \"labels\"\n",
    "if label_dir.exists():\n",
    "    label_files = sorted([f for f in label_dir.iterdir() if f.suffix == \".txt\"])\n",
    "    if label_files:\n",
    "        sample = label_files[0]\n",
    "        print(f\"  File: {sample.name}\")\n",
    "        with open(sample, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "        for line in lines[:10]:  # Show first 10 annotations\n",
    "            parts = line.strip().split()\n",
    "            class_id = parts[0]\n",
    "            print(f\"    class={class_id}  bbox={' '.join(parts[1:])}\")\n",
    "        if len(lines) > 10:\n",
    "            print(f\"    ... ({len(lines)} total annotations in this file)\")\n",
    "    else:\n",
    "        print(\"  âš  No .txt label files found\")\n",
    "else:\n",
    "    print(\"  âš  train/labels/ folder not found\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5530559e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE: ['ambulan', 'bis', 'mobil', 'motor', 'pemadam-kebakaran', 'polisi', 'truk']\n",
      "AFTER:  ['ambulance', 'bus', 'voiture', 'moto', 'camion de pompiers', 'voiture de police', 'camion']\n",
      "\n",
      "âœ“ data.yaml updated at /content/drive/MyDrive/GreenFlow-Rabat/CCTV.v9i.yolov8/data.yaml\n"
     ]
    }
   ],
   "source": [
    "# ---------- Step 3.2: Remap Class Names (Indonesian â†’ French) ----------\n",
    "# The global dataset uses Indonesian labels. We standardize to French\n",
    "# before uploading to Roboflow so every class name is consistent.\n",
    "#\n",
    "# Mapping:\n",
    "#   0: ambulan           â†’ ambulance\n",
    "#   1: bis               â†’ bus\n",
    "#   2: mobil             â†’ voiture\n",
    "#   3: motor             â†’ moto\n",
    "#   4: pemadam-kebakaran â†’ camion de pompiers\n",
    "#   5: polisi            â†’ voiture de police\n",
    "#   6: truk              â†’ camion\n",
    "\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "yaml_path = Path(\"/content/drive/MyDrive/GreenFlow-Rabat/CCTV.v9i.yolov8/data.yaml\")\n",
    "\n",
    "# Read current config\n",
    "with open(yaml_path, \"r\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "print(\"BEFORE:\", cfg[\"names\"])\n",
    "\n",
    "# Replace names (class indices stay the same â€” no label file edits needed)\n",
    "cfg[\"names\"] = [\n",
    "    \"ambulance\",            # 0\n",
    "    \"bus\",                  # 1\n",
    "    \"voiture\",              # 2\n",
    "    \"moto\",                 # 3\n",
    "    \"camion de pompiers\",   # 4\n",
    "    \"voiture de police\",    # 5\n",
    "    \"camion\",               # 6\n",
    "]\n",
    "\n",
    "# Write back â€” safe_dump preserves YOLO-compatible formatting\n",
    "with open(yaml_path, \"w\") as f:\n",
    "    yaml.safe_dump(cfg, f, default_flow_style=False, allow_unicode=True)\n",
    "\n",
    "print(\"AFTER: \", cfg[\"names\"])\n",
    "print(f\"\\nâœ“ data.yaml updated at {yaml_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
