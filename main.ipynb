{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c38acb00",
   "metadata": {},
   "source": [
    "# ðŸŸ¢ GreenFlow Rabat â€” Edge AI Traffic Intelligence\n",
    "## Hackathon RamadnIA 2026\n",
    "\n",
    "**Pipeline:** CCTV â†’ RTSP â†’ Edge Device (YOLO11n) â†’ JSON Webhook â†’ n8n Orchestration\n",
    "\n",
    "**Classes:**\n",
    "| ID | Label | Description |\n",
    "|----|-------|-------------|\n",
    "| 0 | License Plate | Moroccan plates |\n",
    "| 1 | Car | Standard vehicles |\n",
    "| 2 | Grand Taxi | Mercedes W123/W124 shared taxis |\n",
    "| 3 | Triporteur | 3-wheeled cargo motos |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14b72bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "GreenFlow Rabat â€” Environment Check\n",
      "==================================================\n",
      "Python:   3.12.12\n",
      "PyTorch:  2.9.0+cu128\n",
      "CUDA:     True\n",
      "GPU:      Tesla T4\n",
      "Platform: Linux x86_64\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 1: Environment Setup & GPU Check\n",
    "# ============================================================\n",
    "# Run this first every session. No HuggingFace, no Colab deps.\n",
    "# Works on: Local machine, Colab, Kaggle, Paperspace.\n",
    "# ============================================================\n",
    "\n",
    "import subprocess, sys\n",
    "\n",
    "def install(pkg):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg])\n",
    "\n",
    "# Core dependencies\n",
    "for package in [\"ultralytics\", \"roboflow\", \"opencv-python-headless\", \"requests\"]:\n",
    "    install(package)\n",
    "\n",
    "import torch, platform\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"GreenFlow Rabat â€” Environment Check\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Python:   {platform.python_version()}\")\n",
    "print(f\"PyTorch:  {torch.__version__}\")\n",
    "print(f\"CUDA:     {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU:      {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"GPU:      None (CPU mode â€” OK for data prep, slow for training)\")\n",
    "print(f\"Platform: {platform.system()} {platform.machine()}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd3ee975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš  Video not found at: path\\to\\YTDown.com_YouTube_Driving-in-Rabat.mp4\n",
      "  Update VIDEO_PATH above, then re-run this cell.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 2: Frame Extraction from Local Rabat Driving Video\n",
    "# ============================================================\n",
    "# Extracts 1 frame every 5 seconds from a 40-min 1080p video.\n",
    "# ~480 frames â†’ sent to Roboflow Label Assist for annotation.\n",
    "# ============================================================\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# ---- CONFIGURATION ----\n",
    "VIDEO_PATH = r\"path\\to\\YTDown.com_YouTube_Driving-in-Rabat.mp4\"  # <-- UPDATE THIS\n",
    "OUTPUT_DIR = Path(\"extracted_frames\")\n",
    "EXTRACT_EVERY_N_SECONDS = 5\n",
    "# ------------------------\n",
    "\n",
    "def extract_frames(video_path: str, output_dir: Path, interval_sec: int = 5) -> int:\n",
    "    \"\"\"Extract frames from video at fixed time intervals.\n",
    "    \n",
    "    Args:\n",
    "        video_path:  Path to the source .mp4 file.\n",
    "        output_dir:  Directory to save extracted .jpg frames.\n",
    "        interval_sec: Seconds between each captured frame.\n",
    "    \n",
    "    Returns:\n",
    "        Number of frames extracted.\n",
    "    \"\"\"\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise FileNotFoundError(f\"Cannot open video: {video_path}\")\n",
    "    \n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    duration_sec = total_frames / fps\n",
    "    frame_interval = int(fps * interval_sec)\n",
    "    \n",
    "    print(f\"Video: {fps:.1f} FPS | {total_frames} frames | {duration_sec/60:.1f} min\")\n",
    "    print(f\"Extracting 1 frame every {interval_sec}s (every {frame_interval} frames)...\")\n",
    "    \n",
    "    saved = 0\n",
    "    frame_idx = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if frame_idx % frame_interval == 0:\n",
    "            filename = output_dir / f\"rabat_{frame_idx:06d}.jpg\"\n",
    "            cv2.imwrite(str(filename), frame)\n",
    "            saved += 1\n",
    "        frame_idx += 1\n",
    "    \n",
    "    cap.release()\n",
    "    print(f\"âœ“ Extracted {saved} frames â†’ {output_dir}/\")\n",
    "    return saved\n",
    "\n",
    "# Execute\n",
    "if os.path.exists(VIDEO_PATH):\n",
    "    n = extract_frames(VIDEO_PATH, OUTPUT_DIR, EXTRACT_EVERY_N_SECONDS)\n",
    "else:\n",
    "    print(f\"âš  Video not found at: {VIDEO_PATH}\")\n",
    "    print(\"  Update VIDEO_PATH above, then re-run this cell.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76c80b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload and label your dataset, and get an API KEY here: https://app.roboflow.com/?model=undefined&ref=undefined\n",
      "loading Roboflow workspace...\n"
     ]
    },
    {
     "ename": "RoboflowError",
     "evalue": "{\"error\":{\"message\":\"Unsupported get request. Workspace with ID \\\"YOUR_WORKSPACE\\\" does not exist or cannot be loaded due to missing permissions.\",\"status\":404,\"type\":\"GraphMethodException\",\"hint\":\"You can see your available workspaces by issuing a GET request to /workspaces\"}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRoboflowError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2969785697.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRoboflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mROBOFLOW_API_KEY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mproject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWORKSPACE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPROJECT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVERSION\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"yolov8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/roboflow/__init__.py\u001b[0m in \u001b[0;36mworkspace\u001b[0;34m(self, the_workspace)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Check if api_key was passed during __init__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mlist_projects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_workspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe_workspace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mWorkspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_projects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe_workspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/roboflow/adapters/rfapi.py\u001b[0m in \u001b[0;36mget_workspace\u001b[0;34m(api_key, workspace_url)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRoboflowError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRoboflowError\u001b[0m: {\"error\":{\"message\":\"Unsupported get request. Workspace with ID \\\"YOUR_WORKSPACE\\\" does not exist or cannot be loaded due to missing permissions.\",\"status\":404,\"type\":\"GraphMethodException\",\"hint\":\"You can see your available workspaces by issuing a GET request to /workspaces\"}}"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 3: Download Base Dataset from Roboflow\n",
    "# ============================================================\n",
    "# Source: CCTV.v9i.yolov8 â€” pre-labeled CCTV footage.\n",
    "# Merged with our Rabat frames after Label Assist annotation.\n",
    "# ============================================================\n",
    "\n",
    "from roboflow import Roboflow\n",
    "\n",
    "# ---- CONFIGURATION ----\n",
    "ROBOFLOW_API_KEY = \"YOUR_API_KEY\"  # <-- UPDATE THIS (Settings > API Key)\n",
    "WORKSPACE = \"YOUR_WORKSPACE\"       # <-- UPDATE THIS\n",
    "PROJECT   = \"YOUR_PROJECT\"         # <-- UPDATE THIS (e.g., \"cctv-xxxxx\")  \n",
    "VERSION   = 9                      # <-- Dataset version number\n",
    "# ------------------------\n",
    "\n",
    "rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
    "project = rf.workspace(WORKSPACE).project(PROJECT)\n",
    "dataset = project.version(VERSION).download(\"yolov8\")\n",
    "\n",
    "print(f\"\\nâœ“ Dataset downloaded to: {dataset.location}\")\n",
    "print(f\"  Train: {dataset.location}/train/\")\n",
    "print(f\"  Valid: {dataset.location}/valid/\")\n",
    "print(f\"  Test:  {dataset.location}/test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5937dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 4: Train YOLO11n on Merged Dataset\n",
    "# ============================================================\n",
    "# YOLO11n chosen over YOLOv8n for:\n",
    "#   - C2PSA attention â†’ better small object detection\n",
    "#   - 20% fewer FLOPs â†’ faster on RPi5/Jetson\n",
    "#   - Same Ultralytics API â†’ zero migration cost\n",
    "# ============================================================\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "# ---- CONFIGURATION ----\n",
    "DATA_YAML    = \"path/to/data.yaml\"   # <-- UPDATE: Roboflow dataset.location + \"/data.yaml\"\n",
    "EPOCHS       = 100\n",
    "IMG_SIZE     = 640                   # Native YOLO input resolution\n",
    "BATCH_SIZE   = 16                   # Reduce to 8 if OOM on free Colab\n",
    "MODEL_BASE   = \"yolo11n.pt\"         # Nano variant for edge deployment\n",
    "PROJECT_NAME = \"greenflow_rabat\"\n",
    "RUN_NAME     = \"v1_cctv_rabat\"\n",
    "# ------------------------\n",
    "\n",
    "model = YOLO(MODEL_BASE)\n",
    "\n",
    "results = model.train(\n",
    "    data=DATA_YAML,\n",
    "    epochs=EPOCHS,\n",
    "    imgsz=IMG_SIZE,\n",
    "    batch=BATCH_SIZE,\n",
    "    project=PROJECT_NAME,\n",
    "    name=RUN_NAME,\n",
    "    \n",
    "    # --- Small Object Optimizations ---\n",
    "    mosaic=1.0,          # Mosaic augmentation: 4 images in 1 â†’ more small objects per batch\n",
    "    scale=0.9,           # Aggressive scale augmentation to simulate far/near objects\n",
    "    mixup=0.15,          # Light mixup to improve generalization\n",
    "    copy_paste=0.1,      # Copy-paste augmentation for rare classes (Triporteur)\n",
    "    \n",
    "    # --- Training Quality ---\n",
    "    patience=15,         # Early stopping if no improvement for 15 epochs\n",
    "    save_period=10,      # Checkpoint every 10 epochs\n",
    "    cos_lr=True,         # Cosine learning rate scheduler\n",
    "    lr0=0.01,            # Initial learning rate\n",
    "    lrf=0.01,            # Final learning rate factor\n",
    "    \n",
    "    # --- Hardware ---\n",
    "    device=0 if torch.cuda.is_available() else \"cpu\",\n",
    "    workers=4,\n",
    "    amp=True,            # Mixed precision (FP16) â€” 2x speedup on GPU\n",
    "    \n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Training complete!\")\n",
    "print(f\"  Best weights: {results.save_dir}/weights/best.pt\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f5f620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 5: Validate & Visualize Results\n",
    "# ============================================================\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "\n",
    "# ---- CONFIGURATION ----\n",
    "BEST_WEIGHTS = \"greenflow_rabat/v1_cctv_rabat/weights/best.pt\"  # <-- auto from training\n",
    "# ------------------------\n",
    "\n",
    "model = YOLO(BEST_WEIGHTS)\n",
    "\n",
    "# Run validation on test set\n",
    "metrics = model.val()\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Validation Results\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"  mAP@0.5:      {metrics.box.map50:.4f}\")\n",
    "print(f\"  mAP@0.5:0.95: {metrics.box.map:.4f}\")\n",
    "print(f\"  Precision:     {metrics.box.mp:.4f}\")\n",
    "print(f\"  Recall:        {metrics.box.mr:.4f}\")\n",
    "\n",
    "# Per-class breakdown\n",
    "class_names = [\"License Plate\", \"Car\", \"Grand Taxi\", \"Triporteur\"]\n",
    "print(\"\\nPer-Class mAP@0.5:\")\n",
    "for i, name in enumerate(class_names):\n",
    "    if i < len(metrics.box.maps):\n",
    "        print(f\"  {name:15s}: {metrics.box.maps[i]:.4f}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd84017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 6: Export Model for Edge Deployment\n",
    "# ============================================================\n",
    "# Export to ONNX (universal) + NCNN (Raspberry Pi optimized)\n",
    "# or TensorRT (Jetson optimized). Choose based on your HW.\n",
    "# ============================================================\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "BEST_WEIGHTS = \"greenflow_rabat/v1_cctv_rabat/weights/best.pt\"\n",
    "model = YOLO(BEST_WEIGHTS)\n",
    "\n",
    "# --- Option A: ONNX (Universal â€” works on RPi5 & Jetson) ---\n",
    "onnx_path = model.export(format=\"onnx\", imgsz=640, half=False, simplify=True)\n",
    "print(f\"âœ“ ONNX exported: {onnx_path}\")\n",
    "\n",
    "# --- Option B: NCNN (Best for Raspberry Pi 5 CPU) ---\n",
    "# Uncomment below for RPi5 deployment:\n",
    "# ncnn_path = model.export(format=\"ncnn\", imgsz=640, half=True)\n",
    "# print(f\"âœ“ NCNN exported: {ncnn_path}\")\n",
    "\n",
    "# --- Option C: TensorRT (Best for Jetson with GPU) ---\n",
    "# Uncomment below for Jetson deployment:\n",
    "# engine_path = model.export(format=\"engine\", imgsz=640, half=True)\n",
    "# print(f\"âœ“ TensorRT exported: {engine_path}\")\n",
    "\n",
    "print(\"\\nDeployment Guide:\")\n",
    "print(\"  RPi5 (CPU):     Use NCNN export â†’ ~10-14 FPS @ 640px\")\n",
    "print(\"  Jetson Nano:    Use TensorRT FP16 â†’ ~30-40 FPS @ 640px\")\n",
    "print(\"  Jetson Orin:    Use TensorRT FP16 â†’ ~80+ FPS @ 640px\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c212f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 7: Real-Time RTSP Inference + n8n Webhook Dispatch\n",
    "# ============================================================\n",
    "# THIS IS THE EDGE DEPLOYMENT SCRIPT.\n",
    "# Runs on RPi5 / Jetson connected to CCTV via RTSP.\n",
    "# Sends lightweight JSON to n8n â€” NEVER sends images.\n",
    "# ============================================================\n",
    "\n",
    "import cv2\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ---- CONFIGURATION ----\n",
    "RTSP_URL     = \"rtsp://admin:password@192.168.1.100:554/stream1\"  # <-- CCTV RTSP URL\n",
    "MODEL_PATH   = \"greenflow_rabat/v1_cctv_rabat/weights/best.onnx\"  # <-- Exported model\n",
    "N8N_WEBHOOK  = \"http://localhost:5678/webhook/greenflow-traffic\"   # <-- n8n webhook URL\n",
    "CONFIDENCE   = 0.4          # Minimum detection confidence\n",
    "REPORT_INTERVAL = 30        # Send report to n8n every N seconds\n",
    "CONGESTION_THRESHOLD = 15   # Vehicle count that triggers \"congested\" alert\n",
    "CLASS_NAMES  = {0: \"license_plate\", 1: \"car\", 2: \"grand_taxi\", 3: \"triporteur\"}\n",
    "# ------------------------\n",
    "\n",
    "def build_traffic_payload(detections: list, fps: float, camera_id: str = \"CAM-RABAT-01\") -> dict:\n",
    "    \"\"\"Build a lightweight JSON payload from detection results.\n",
    "    \n",
    "    Privacy-by-Design: NO images, NO coordinates â€” only counts and metadata.\n",
    "    \"\"\"\n",
    "    counts = defaultdict(int)\n",
    "    confidences = defaultdict(list)\n",
    "    \n",
    "    for det in detections:\n",
    "        cls_id = int(det.cls)\n",
    "        cls_name = CLASS_NAMES.get(cls_id, f\"unknown_{cls_id}\")\n",
    "        counts[cls_name] += 1\n",
    "        confidences[cls_name].append(float(det.conf))\n",
    "    \n",
    "    total_vehicles = counts.get(\"car\", 0) + counts.get(\"grand_taxi\", 0) + counts.get(\"triporteur\", 0)\n",
    "    \n",
    "    # Congestion level logic\n",
    "    if total_vehicles >= CONGESTION_THRESHOLD * 2:\n",
    "        congestion = \"CRITICAL\"\n",
    "    elif total_vehicles >= CONGESTION_THRESHOLD:\n",
    "        congestion = \"HIGH\"\n",
    "    elif total_vehicles >= CONGESTION_THRESHOLD * 0.5:\n",
    "        congestion = \"MODERATE\"\n",
    "    else:\n",
    "        congestion = \"LOW\"\n",
    "    \n",
    "    # Green light recommendation (consultative architecture)\n",
    "    if congestion in (\"CRITICAL\", \"HIGH\"):\n",
    "        green_advice_sec = 90   # Extend green to flush queue\n",
    "    elif congestion == \"MODERATE\":\n",
    "        green_advice_sec = 45   # Standard duration\n",
    "    else:\n",
    "        green_advice_sec = 20   # Short green, low traffic\n",
    "    \n",
    "    return {\n",
    "        \"camera_id\": camera_id,\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"fps\": round(fps, 1),\n",
    "        \"total_vehicles\": total_vehicles,\n",
    "        \"congestion_level\": congestion,\n",
    "        \"green_light_advice_seconds\": green_advice_sec,\n",
    "        \"vehicle_counts\": dict(counts),\n",
    "        \"avg_confidence\": {k: round(sum(v)/len(v), 3) for k, v in confidences.items()},\n",
    "        \"license_plates_detected\": counts.get(\"license_plate\", 0),\n",
    "    }\n",
    "\n",
    "\n",
    "def send_to_n8n(payload: dict, webhook_url: str) -> bool:\n",
    "    \"\"\"Send JSON payload to n8n webhook. Fail silently on network error.\"\"\"\n",
    "    try:\n",
    "        resp = requests.post(webhook_url, json=payload, timeout=5)\n",
    "        return resp.status_code == 200\n",
    "    except requests.RequestException:\n",
    "        return False\n",
    "\n",
    "\n",
    "def run_edge_inference(rtsp_url: str, model_path: str, webhook_url: str):\n",
    "    \"\"\"Main inference loop for edge deployment.\"\"\"\n",
    "    \n",
    "    model = YOLO(model_path, task=\"detect\")\n",
    "    cap = cv2.VideoCapture(rtsp_url)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"ERROR: Cannot connect to RTSP stream: {rtsp_url}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Connected to {rtsp_url}\")\n",
    "    print(f\"Sending reports to n8n every {REPORT_INTERVAL}s\")\n",
    "    print(\"Press Ctrl+C to stop.\\n\")\n",
    "    \n",
    "    last_report_time = time.time()\n",
    "    frame_count = 0\n",
    "    fps_start = time.time()\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Stream interrupted. Reconnecting in 5s...\")\n",
    "                time.sleep(5)\n",
    "                cap = cv2.VideoCapture(rtsp_url)\n",
    "                continue\n",
    "            \n",
    "            # Run inference\n",
    "            results = model(frame, conf=CONFIDENCE, verbose=False)\n",
    "            frame_count += 1\n",
    "            \n",
    "            # Calculate FPS\n",
    "            elapsed = time.time() - fps_start\n",
    "            current_fps = frame_count / elapsed if elapsed > 0 else 0\n",
    "            \n",
    "            # Periodic n8n report\n",
    "            if time.time() - last_report_time >= REPORT_INTERVAL:\n",
    "                if results[0].boxes is not None and len(results[0].boxes) > 0:\n",
    "                    payload = build_traffic_payload(results[0].boxes, current_fps)\n",
    "                    sent = send_to_n8n(payload, webhook_url)\n",
    "                    status = \"SENT\" if sent else \"QUEUED (n8n offline)\"\n",
    "                    print(f\"[{payload['timestamp']}] {payload['congestion_level']:8s} | \"\n",
    "                          f\"Vehicles: {payload['total_vehicles']:3d} | \"\n",
    "                          f\"FPS: {current_fps:.1f} | \"\n",
    "                          f\"Green Advice: {payload['green_light_advice_seconds']}s | {status}\")\n",
    "                \n",
    "                last_report_time = time.time()\n",
    "                frame_count = 0\n",
    "                fps_start = time.time()\n",
    "                \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nStopped by user.\")\n",
    "    finally:\n",
    "        cap.release()\n",
    "\n",
    "# ---- Uncomment to run on the edge device ----\n",
    "# run_edge_inference(RTSP_URL, MODEL_PATH, N8N_WEBHOOK)\n",
    "print(\"Edge inference script ready.\")\n",
    "print(\"Uncomment the last line and run on your RPi5/Jetson.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd16ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 8: Simulate Edge Inference on a Test Image/Video\n",
    "# ============================================================\n",
    "# Use this to demo the pipeline without an RTSP camera.\n",
    "# Feed it a local video or image and see the JSON output.\n",
    "# ============================================================\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import cv2, json\n",
    "\n",
    "BEST_WEIGHTS = \"greenflow_rabat/v1_cctv_rabat/weights/best.pt\"\n",
    "TEST_SOURCE  = \"path/to/test_video_or_image.mp4\"  # <-- UPDATE THIS\n",
    "CLASS_NAMES  = {0: \"license_plate\", 1: \"car\", 2: \"grand_taxi\", 3: \"triporteur\"}\n",
    "\n",
    "model = YOLO(BEST_WEIGHTS)\n",
    "results = model(TEST_SOURCE, conf=0.4, save=True, stream=False)\n",
    "\n",
    "# Build sample payload from first result\n",
    "for r in results:\n",
    "    counts = defaultdict(int)\n",
    "    if r.boxes is not None:\n",
    "        for box in r.boxes:\n",
    "            cls_name = CLASS_NAMES.get(int(box.cls), \"unknown\")\n",
    "            counts[cls_name] += 1\n",
    "    \n",
    "    sample_payload = {\n",
    "        \"camera_id\": \"DEMO-01\",\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"total_vehicles\": counts.get(\"car\", 0) + counts.get(\"grand_taxi\", 0) + counts.get(\"triporteur\", 0),\n",
    "        \"vehicle_counts\": dict(counts),\n",
    "        \"congestion_level\": \"HIGH\" if sum(counts.values()) > 10 else \"LOW\",\n",
    "        \"green_light_advice_seconds\": 90 if sum(counts.values()) > 10 else 30,\n",
    "    }\n",
    "    \n",
    "    print(\"Sample n8n Webhook Payload:\")\n",
    "    print(json.dumps(sample_payload, indent=2))\n",
    "    break  # Show first frame only\n",
    "\n",
    "print(f\"\\nAnnotated results saved to: {results[0].save_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
